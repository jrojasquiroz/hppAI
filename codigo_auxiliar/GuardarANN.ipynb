{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0008eede-3b6b-4b5f-8d40-d4089254ee1e",
   "metadata": {},
   "source": [
    "# Elaboración del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1400fd3-1b48-4485-b12b-7ccb49958542",
   "metadata": {},
   "source": [
    "En la siguiente celda voy a incluir todo el proceso de limpieza del dataframe que ya hemos visto en clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b07502b-c090-45aa-b3c8-316dc6748e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #permite manipular los dataframes, que serían el equivalente a los Excel\n",
    "import numpy as np #en caso se necesiten cálculos numéricos, como p. ej. encontrar valores nulos \n",
    "from sklearn.model_selection import train_test_split #para dividir datos en entrenamiento y testeo\n",
    "from sklearn import preprocessing #para escalar/normalizar variables numéricas\n",
    "import tensorflow as tf #Esta y las de abajo las necesitamos siempre para ANN y RF\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score #para calcular parámetros del modelo\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6884355b-5ebf-4fdc-a21c-320488303b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "base=pd.read_csv('rawdata/habitaclia4043.csv')\n",
    "\n",
    "#Elimino variables que no aportan o son repetitivas\n",
    "noimportan=base[['Unnamed: 0', 'OBJECTID_1', 'codigo_inmueble1', 'Title', 'Type_build', 'Type_opera', \n",
    "     'Link', 'Location', 'Lat_X', 'Lon_Y', 'Climatic_Z', 'Nom_Mun','Dum_precio','COD_MUN',\n",
    "     'COD_MUN','precio_eur','Unit_price','Ln_unit_pr',\n",
    "            'calificacion_emision_valor','ascensor','C_contempo', 'C_estado', 'C_armarios', 'B_contempo', \n",
    "            'B_estado', 'B_lavamano', 'R_contempo', 'R_estado', 'R_carpinte', 'R_singular', \n",
    "            'R_ventana', 'Precio_red', 'scrap_year','Muestra_2023']]\n",
    "base=base.drop(noimportan.columns,axis=1)\n",
    "\n",
    "#Elimino variables no numéricas\n",
    "no_numericas = base.select_dtypes(exclude=['number']).columns\n",
    "base=base.drop(no_numericas, axis=1)\n",
    "\n",
    "base=base.dropna(subset=['Estado_contemporaneidad_calidad','Ausencia_singulares_presencia_arm_cocina'])\n",
    "\n",
    "base=base.drop(['ratio_bano_hab','Inverse_Age'],axis=1)\n",
    "\n",
    "X = base.drop('Ln_total_pr', axis=1)  # Todas las columnas excepto 'Ln_total_pr'\n",
    "y = base['Ln_total_pr']  # Columna 'Ln_total_pr'\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y testeo\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                                    X, y, \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=42 #Puede ser cualquier número\n",
    "                                                    )\n",
    "\n",
    "OHE=X_train[['Year_Before_1981', 'Year_1982_2006', 'Year_After_2007',\n",
    "       'grand_terr_20m2', 'superficie_jardin_m2', 'bool_despacho',\n",
    "       'bool_buhardilla', 'bool_trastero', 'bool_lavadero',\n",
    "       'bool_piscina_comunitaria', 'bool_jardin_comunitario', 'bool_amueblado',\n",
    "       'bool_ascensor', 'bool_aire_acondicionado', 'bool_calefaccion',\n",
    "       'bool_chimenea', 'Dum_EPC', 'EPC_A_emision', 'EPC_B_emision',\n",
    "       'EPC_C_emision', 'EPC_D_emision', 'EPC_E_emision', 'EPC_F_emision',\n",
    "       'EPC_G_emision', 'dum_acces_viappal', 'calidad_cocina', 'diseny_cocina',\n",
    "       'alta_calidad', 'reform_inmob', 'dum_mar_200m', 'dum_ttpp_riel_urb',\n",
    "       'EPC_A_emision_2023', 'EPC_B_emision_2023', 'EPC_C_emision_2023',\n",
    "       'EPC_D_emision_2023', 'EPC_E_emision_2023', 'EPC_F_emision_2023',\n",
    "       'EPC_G_emision_2023']]\n",
    "\n",
    "# Crear una lista con todas las columnas binarias\n",
    "columnas_a_eliminar = list(OHE.columns)\n",
    "\n",
    "# Eliminar las columnas binarias de X_trainOLS para quedarme sólo con las numéricas\n",
    "X2 = X_train.drop(columns=columnas_a_eliminar)\n",
    "\n",
    "#Estandarizamos los valores de X3\n",
    "min_max_scaler = preprocessing.MinMaxScaler() #preprocessing es una función de la librearía \n",
    "                                              #sklearn, ya sabe lo que hacer\n",
    "X3 = min_max_scaler.fit_transform(X2)\n",
    "\n",
    "# Convertir OHE a un array NumPy\n",
    "OHE_array=OHE.values\n",
    "\n",
    "# Concatenar X3, y OHE_array a lo largo del eje de las columnas (axis=1)\n",
    "Xtrain_scale = np.concatenate((X3,OHE_array), axis=1)\n",
    "\n",
    "ytrain_array = y_train.values\n",
    "\n",
    "OHE2=X_test[['Year_Before_1981', 'Year_1982_2006', 'Year_After_2007',\n",
    "       'grand_terr_20m2', 'superficie_jardin_m2', 'bool_despacho',\n",
    "       'bool_buhardilla', 'bool_trastero', 'bool_lavadero',\n",
    "       'bool_piscina_comunitaria', 'bool_jardin_comunitario', 'bool_amueblado',\n",
    "       'bool_ascensor', 'bool_aire_acondicionado', 'bool_calefaccion',\n",
    "       'bool_chimenea', 'Dum_EPC', 'EPC_A_emision', 'EPC_B_emision',\n",
    "       'EPC_C_emision', 'EPC_D_emision', 'EPC_E_emision', 'EPC_F_emision',\n",
    "       'EPC_G_emision', 'dum_acces_viappal', 'calidad_cocina', 'diseny_cocina',\n",
    "       'alta_calidad', 'reform_inmob', 'dum_mar_200m', 'dum_ttpp_riel_urb',\n",
    "       'EPC_A_emision_2023', 'EPC_B_emision_2023', 'EPC_C_emision_2023',\n",
    "       'EPC_D_emision_2023', 'EPC_E_emision_2023', 'EPC_F_emision_2023',\n",
    "       'EPC_G_emision_2023']]\n",
    "\n",
    "# Crear una lista con todas las columnas binarias\n",
    "columnas_a_eliminar = list(OHE2.columns)\n",
    "\n",
    "# Eliminar las columnas binarias de X_testOLS para quedarme sólo con las numéricas\n",
    "X2_2 = X_test.drop(columns=columnas_a_eliminar)\n",
    "\n",
    "#Estandarizamos los valores de X3\n",
    "X3_2 = min_max_scaler.fit_transform(X2_2)\n",
    "\n",
    "# Convertir OHE a un array NumPy\n",
    "OHE2_array=OHE2.values\n",
    "\n",
    "# Concatenar X3, y OHE_array a lo largo del eje de las columnas (axis=1)\n",
    "Xtest_scale = np.concatenate((X3_2,OHE2_array), axis=1)\n",
    "\n",
    "# Convierto la Y en array también\n",
    "ytest_array = y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4686a69-60f8-4ceb-bebf-99862d0c936a",
   "metadata": {},
   "source": [
    "Para no volver a repetir todo el proceso de limpieza de datos, voy a guardar los que termino usando, que son `Xtest_scale` y `ytest_array`. De esta forma, para una próxima vez sólo debo 'llamar' a estos arrays (que se guardan en formato de *numpy*). Verán cómo hacer esa llamada en el siguiente cuaderno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b92a323d-0edf-4b6b-83d2-2f1d12e7ec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/Xtrain_scale.npy', Xtrain_scale)\n",
    "np.save('data/ytrain_array.npy', ytrain_array)\n",
    "\n",
    "np.save('data/Xtest_scale.npy', Xtest_scale)\n",
    "np.save('data/ytest_array.npy', ytest_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78968fa7-899d-4a39-9b1b-1bdb5e4a3b6c",
   "metadata": {},
   "source": [
    "Ahora estructuro el modelo. No se preocupen por el warning, ya lo he revisado y no es nada de qué preocuparse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d70253d5-998a-4080-bdc1-a38cd3ca1c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paul_\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Añado una semilla de aleatorización\n",
    "seed_value = 42\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "#Defino el modelo\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu',\n",
    "    input_shape=(161,)), #### Noten que acá va la cantidad de X #####\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1,activation='relu') \n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.005), #Valor usado en la literatura\n",
    "    loss='mean_squared_error'\n",
    ")\n",
    "\n",
    "nnmodel = model.fit(Xtrain_scale, ytrain_array, epochs=100, #Valor usado en la literatura\n",
    "               batch_size=6, #Valor usado en la literatura\n",
    "               verbose=False, #Sólo para que no imprima muchas cosas mientras procesa el modelo\n",
    "               callbacks=[EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)], #Valores usados en la literatura\n",
    "               validation_split=0.2 #Valor usado en la literatura\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c29f3b8-23f9-4277-91a6-3a33a947eebe",
   "metadata": {},
   "source": [
    "Reviso el rendimiento del modelo con los datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19a9c0ea-a133-4056-935f-d1e515804b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Coefficient of Determination (R2): 0.5176558230479482\n",
      "Adjusted Coefficient of Determination(R2 adj): 0.4209467165855817\n",
      "Root Mean Squared Error (RMSE): 0.37535636139788636\n"
     ]
    }
   ],
   "source": [
    "# Predicciones en el conjunto de testeo\n",
    "y_predANN = model.predict(Xtest_scale)\n",
    "\n",
    "# Coefficient of determination (R2)\n",
    "r2ANN = r2_score(ytest_array, y_predANN)\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "rmseANN = np.sqrt(mean_squared_error(ytest_array, y_predANN))\n",
    "\n",
    "# Calcular n y k\n",
    "n = len(ytest_array)  # Número de observaciones\n",
    "k = Xtest_scale.shape[1]  # Número de variables independientes\n",
    "\n",
    "# Calcular R^2 ajustado\n",
    "r2ANN_adjusted = 1 - ((1 - r2ANN) * (n - 1) / (n - k - 1))\n",
    "\n",
    "# Imprimir resultados\n",
    "print(\"Coefficient of Determination (R2):\", r2ANN)\n",
    "print(\"Adjusted Coefficient of Determination(R2 adj):\", r2ANN_adjusted)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmseANN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26206d5-ffa5-4f91-8dbd-e3fef9bad770",
   "metadata": {},
   "source": [
    "Ahora guardaré el modelo en el formato *.h5*, que es algo que no tenía el código que vimos en clase. Y el historial en formato *.pickle* (antes estaba con *.pkl*). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54d24e62-1f81-4909-9d11-f928601093aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Guardar el modelo\n",
    "model.save(\"model/NN5-BCN4K.h5\")\n",
    "\n",
    "# Guardar el historial\n",
    "with open(\"model/history-NN5-BCN4K.pickle\", \"wb\") as f:\n",
    "    pickle.dump(nnmodel.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c582a18-3c77-4379-ab3f-7b089a506c6a",
   "metadata": {},
   "source": [
    "Lo que sugiere el warning es guardar el modelo en formato *.keras* en lugar de *.h5*. Lo guardaré también en ese formato para que vean que el resultado es el mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c2557e2-142c-48a6-b5c3-380888f9378e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo\n",
    "model.save(\"model/NN5-BCN4K.keras\")\n",
    "\n",
    "#Ya no guardo el historial porque el warning no era sobre él."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c4a032-117e-4ba6-ad4b-11e3b2a960f9",
   "metadata": {},
   "source": [
    "# Cargo el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54749cb-f006-47a8-9825-c5ab04a28103",
   "metadata": {},
   "source": [
    "<mark>Ahora supongamos lo siguiente</mark>: ya han obtenido el modelo y guardado sus resultados. Sin embargo, han cerrado el Jupyter Lab y al volver a abrirlo quieren cargar los resultados idénticos que obtuvieron antes. \n",
    "\n",
    "A continuación les muestro cómo hacerlo, ya sea que hayan guardado su modelo en formato *.h5* o *.keras*. No necesitan guardar el modelo en ambos formatos, yo lo hago sólo para que noten que el resultado es el mismo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77af1a0c-a329-4ce3-82e4-aa01a8762686",
   "metadata": {},
   "source": [
    "## Archivo *.h5*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d2e45c-2819-4e69-84a9-8b279cc7c922",
   "metadata": {},
   "source": [
    "Voy a importar el modelo con formato *.h5* en el objeto `loaded_model`. El warning nos indica que debemos construir las métricas, y es lo que buscamos hacer con las siguientes celdas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab87dd8f-eaa0-4da9-9155-dbfe4a6d2b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Cargar el modelo\n",
    "loaded_model = load_model(\"model/NN5-BCN4K.h5\")\n",
    "\n",
    "# Cargar el historial\n",
    "with open(\"model/history-NN5-BCN4K.pickle\", \"rb\") as f:\n",
    "    loaded_history = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183bd68c-623f-4c73-8a9c-b6ae06432ebd",
   "metadata": {},
   "source": [
    "Como no quiero volver a hacer todo el proceso de importación y limpieza de datos, sólo voy a importar aquellos que guardé anteriormente. Ojo, <mark>recuerden que nos estamos poniendo en la situación que he reiniciado el Jupyter Lab y por ello mi PC no 'recuerda' a mis arrays.</mark>\n",
    "\n",
    "Cargo sólo los datos de prueba porque es sobre ellos que estoy calculando las métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c197bac6-a85a-45be-8589-a8711cc8e8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest_scale=np.load('data/Xtest_scale.npy')\n",
    "ytest_array=np.load('data/ytest_array.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae82141b-8ba2-4463-ae66-bca8e2645886",
   "metadata": {},
   "source": [
    "Y ahora puedo ver mis métricas llamando a `loaded_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bfb0e4e-6f26-40c7-bfef-96e9d0831b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Coefficient of Determination (R2): 0.5176558230479482\n",
      "Adjusted Coefficient of Determination(R2 adj): 0.4209467165855817\n",
      "Root Mean Squared Error (RMSE): 0.37535636139788636\n"
     ]
    }
   ],
   "source": [
    "# Predicciones en el conjunto de testeo\n",
    "y_predANN = loaded_model.predict(Xtest_scale) #noten que ahora llamo a 'loaded_model'\n",
    "\n",
    "# Coefficient of determination (R2)\n",
    "r2ANN = r2_score(ytest_array, y_predANN)\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "rmseANN = np.sqrt(mean_squared_error(ytest_array, y_predANN))\n",
    "\n",
    "# Calcular n y k\n",
    "n = len(ytest_array)  # Número de observaciones\n",
    "k = Xtest_scale.shape[1]  # Número de variables independientes\n",
    "\n",
    "# Calcular R^2 ajustado\n",
    "r2ANN_adjusted = 1 - ((1 - r2ANN) * (n - 1) / (n - k - 1))\n",
    "\n",
    "# Imprimir resultados\n",
    "print(\"Coefficient of Determination (R2):\", r2ANN)\n",
    "print(\"Adjusted Coefficient of Determination(R2 adj):\", r2ANN_adjusted)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmseANN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9f81a3-ecea-4414-90b7-83ef79693b9b",
   "metadata": {},
   "source": [
    "Como notan, son idénticas a las que obtuve inicialmente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dba304-349d-4079-9c77-41349ed4112c",
   "metadata": {},
   "source": [
    "## Archivo *.keras*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86c8a3b-5ec3-471c-b946-79c9e4630b11",
   "metadata": {},
   "source": [
    "Ahora importaré el modelo en el objeto `loaded_model2`. El motivo por el que no me gusta usar este formato (*.keras*) es por el warning: indica que el optimizador (entiendo, el de Adam) está usando menos variables de las que tenía mientras se entrenó. Sin embargo, como verán después, el resultado es exactamente igual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb05c649-698f-4dc3-b979-ac686777f342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paul_\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:396: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 8 variables whereas the saved optimizer has 14 variables. \n",
      "  trackable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Cargar el modelo\n",
    "loaded_model2 = load_model(\"model/NN5-BCN4K.keras\") #noten que ahora llamo al archivo .keras, antes era el .h5\n",
    "\n",
    "# Cargar el historial\n",
    "with open(\"model/history-NN5-BCN4K.pickle\", \"rb\") as f:\n",
    "    loaded_history = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d7f1b99-04e1-435b-a77b-6d1803e8e26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Coefficient of Determination (R2): 0.5176558230479482\n",
      "Adjusted Coefficient of Determination(R2 adj): 0.4209467165855817\n",
      "Root Mean Squared Error (RMSE): 0.37535636139788636\n"
     ]
    }
   ],
   "source": [
    "# Predicciones en el conjunto de testeo\n",
    "y_predANN = loaded_model2.predict(Xtest_scale) #noten que ahora llamo a 'loaded_model'\n",
    "\n",
    "# Coefficient of determination (R2)\n",
    "r2ANN = r2_score(ytest_array, y_predANN)\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "rmseANN = np.sqrt(mean_squared_error(ytest_array, y_predANN))\n",
    "\n",
    "# Calcular n y k\n",
    "n = len(ytest_array)  # Número de observaciones\n",
    "k = Xtest_scale.shape[1]  # Número de variables independientes\n",
    "\n",
    "# Calcular R^2 ajustado\n",
    "r2ANN_adjusted = 1 - ((1 - r2ANN) * (n - 1) / (n - k - 1))\n",
    "\n",
    "# Imprimir resultados\n",
    "print(\"Coefficient of Determination (R2):\", r2ANN)\n",
    "print(\"Adjusted Coefficient of Determination(R2 adj):\", r2ANN_adjusted)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmseANN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
