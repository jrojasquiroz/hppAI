{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e38fc4a-305c-484f-9245-476932d7c035",
   "metadata": {},
   "source": [
    "# LLM para crear un indicador de calidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a4bd8c-7e22-4025-a65b-a23e84c3f9e2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Primer modelo (4k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215e576b-a4ba-4bb4-abae-b2f0a7cfa54d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991574c9-a523-4190-80e1-9e305e832e5d",
   "metadata": {},
   "source": [
    "Con la BBDD de Carlos, voy a crear un modelo que, a partir de un indicador de calidad, aprenda a reconocer qué descripciones corresponden a inmuebles de buena calidad. Usaremos un modelo del tipo como una máquina de vectores de soporte (SVM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ecd57bb-d2d8-4b96-a1e6-3a6360888ac1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyreadstat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec26856-7564-45c8-a901-ef3120450792",
   "metadata": {},
   "source": [
    "Importamos el archivo, revisamos las columnas, nos quedamos sólo con las que nos interesan y vemos cuántas filas tenemos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08216e5b-ee94-4028-a074-0033a6f732a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "h=pd.read_spss('rawdata/BDDHabitaclia_4043_join.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dcf9ace-6302-4476-95b1-a6e67b88d0a2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OBJECTID_1', 'codigo_inmueble1', 'Title', 'Type_build', 'Type_opera', 'Link', 'Location', 'Lat_X', 'Lon_Y', 'Climatic_Z', 'Nom_Mun', 'precio_eur', 'superficie', 'superficie_2', 'Unit_price', 'Ln_total_pr', 'Ln_unit_pr', 'numero_habitaciones', 'numero_bano', 'ratio_bano_hab', 'numero_aseo', 'ascensor', 'interac_planta', 'numero_de_piso', 'anyo_constr', 'anyo_constr_ponderad', 'antig_ponderad', 'Inverse_Age', 'Year_Before_1981', 'Year_1982_2006', 'Year_After_2007', 'superficie_terraza_m2', 'grand_terr_20m2', 'superficie_jardin_m2', 'superficie_salon', 'bool_despacho', 'bool_buhardilla', 'bool_trastero', 'bool_lavadero', 'bool_piscina_comunitaria', 'bool_jardin_comunitario', 'bool_amueblado', 'bool_ascensor', 'descripcion', 'bool_aire_acondicionado', 'bool_calefaccion', 'bool_chimenea', 'texto_destacado', 'Description', 'calificacion_consumo_letra', 'calificacion_consumo_valor', 'calificacion_emision_letra', 'calificacion_emision_valor', 'Dum_EPC', 'EPC_A_emision', 'EPC_B_emision', 'EPC_C_emision', 'EPC_D_emision', 'EPC_E_emision', 'EPC_F_emision', 'EPC_G_emision', 'COD_MUN', 'temp_enero', 'temp_julio', 'radiacion_enero', 'radiacion_julio', 'POB_91', 'POB_01', 'POB_06', 'POR_01', 'LTL1991_M', 'LTL_2001', 'DLTL_MUN', 'RW', 'FLE', 'FLS', 'SUP_URB_90', 'SUP_URB_00', 'Job_ratio_01', 'Autocontencion_01', 'Nodalidad_01', 'Dist_CBD', 'Dist_CBD2', 'Dist_sub_center', 'Elevation_Mean', 'dum_acces_viappal', 'IND_pr', 'FIRE_pr', 'Div_LandUse', 'COD_SEC', 'pr_directivo', 'pr_tecnico_prof', 'pr_tecnico_apoyo', 'pr_empl_admin', 'pr_restaur_comer', 'pr_agri_calificado', 'pr_artesano', 'pr_operador', 'pr_no_calif', 'desplaz_ponderado', 'plant_ras_pond', 'edif_ruin_pr', 'edif_malo_pr', 'edif_deficient_pr', 'edif_bueno_pr', 'Doorman_pr', 'opin_ruido_si_pr', 'opin_contam_si_pr', 'opin_calle_sucia_pr', 'opin_mala_comunic_pr', 'opin_pocazonaverde_pr', 'opin_delincuencia_pr', 'opin_falta_aseo_pr', 'local_salud_pr', 'local_edu_pr', 'local_social_pr', 'local_cult_pr', 'local_comerc_pr', 'local_oficinas_pr', 'local_industr_pr', 'local_agrar_pr', 'POB_TOTAL', 'POB_RESID', 'LOC_TOTAL', 'POR_TOTAL', 'LOC_VIV_TOTAL', 'dens_loc_100hab', 'dens_loc_sup', 'dens_pob_sup', 'estud_sin_pr', 'estud_primer_pr', 'estud_segund_pr', 'estud_tercer_pr', 'VIV_ppales_TOTAL', 'Sup_viv_sec', 'viv_ppales_pr', 'viv_no_ppales_pr', 'viv_secundarias_pr', 'viv_vacias_pr', 'viv_unifam_pr', 'viv_aptos_pr', 'resi_euro_pr', 'resi_africa_pr', 'resi_america_pr', 'resi_asia_pr', 'resi_oceania_pr', 'H_ocup_POR', 'H_loc_INE', 'H_tamaviv', 'H_ocup_POR_Xpor', 'H_loc_INE_XLOCS', 'H_tamaviv_Xvivs', 'CT_renta_alta_CPA', 'CT_renta_meda_CPA', 'CT_renta_medb_CPA', 'Income_Household_2016', 'DP2e', 'Dens_Time_total', 'Dens_Time_total_work', 'Dens_Time_total_Nwork', 'Dens_pers_act_total', 'Dens_pers_act_working', 'Dens_pers_act_Nworking', 'Div_total_work', 'Div_act_work', 'Div_socio_work', 'Div_total_Nwork', 'Div_act_Nwork', 'Div_socio_Nwork', 'calidad_cocina', 'diseny_cocina', 'alta_calidad', 'reform_inmob', 'dum_mar_200m', 'dum_ttpp_riel_urb', 'dist_near_riel_km', 'dist_near_viappal_km', 'C_contempo', 'C_estado', 'C_armarios', 'B_contempo', 'B_estado', 'B_lavamano', 'R_contempo', 'R_estado', 'R_carpinte', 'R_singular', 'R_ventana', 'Dum_precio', 'Precio_red', 'scrap_year', 'persona', 'filter_$', 'FAC1_1', 'FAC2_1', 'Muestra_2023', 'EPC_A_emision_2023', 'EPC_B_emision_2023', 'EPC_C_emision_2023', 'EPC_D_emision_2023', 'EPC_E_emision_2023', 'EPC_F_emision_2023', 'EPC_G_emision_2023']\n"
     ]
    }
   ],
   "source": [
    "print(h.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61ac1a55-7a34-4034-88dd-7e0bfe947c53",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID_1</th>\n",
       "      <th>codigo_inmueble1</th>\n",
       "      <th>precio_eur</th>\n",
       "      <th>Unit_price</th>\n",
       "      <th>texto_destacado</th>\n",
       "      <th>calidad_cocina</th>\n",
       "      <th>diseny_cocina</th>\n",
       "      <th>alta_calidad</th>\n",
       "      <th>reform_inmob</th>\n",
       "      <th>C_contempo</th>\n",
       "      <th>C_estado</th>\n",
       "      <th>C_armarios</th>\n",
       "      <th>B_contempo</th>\n",
       "      <th>B_estado</th>\n",
       "      <th>B_lavamano</th>\n",
       "      <th>R_contempo</th>\n",
       "      <th>R_estado</th>\n",
       "      <th>R_carpinte</th>\n",
       "      <th>R_singular</th>\n",
       "      <th>R_ventana</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.872004e+12</td>\n",
       "      <td>345000.0</td>\n",
       "      <td>4011.627907</td>\n",
       "      <td>Unico!!! Dúplex en Collblanc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.020004e+12</td>\n",
       "      <td>370000.0</td>\n",
       "      <td>3814.432990</td>\n",
       "      <td>Piso en venta con amplio balcón junto al CC Gr...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>8.700366e+10</td>\n",
       "      <td>169000.0</td>\n",
       "      <td>2194.805195</td>\n",
       "      <td>TODO EXTERIOR Y REFORMADO</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.000037e+11</td>\n",
       "      <td>229000.0</td>\n",
       "      <td>2410.526316</td>\n",
       "      <td>Piso para entrar a vivir</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.380035e+11</td>\n",
       "      <td>393000.0</td>\n",
       "      <td>2411.042945</td>\n",
       "      <td>de obra nueva a estrenar. 4hab</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID_1  codigo_inmueble1  precio_eur   Unit_price  \\\n",
       "0         1.0      2.872004e+12    345000.0  4011.627907   \n",
       "1         2.0      5.020004e+12    370000.0  3814.432990   \n",
       "2         3.0      8.700366e+10    169000.0  2194.805195   \n",
       "3         4.0      5.000037e+11    229000.0  2410.526316   \n",
       "4         5.0      5.380035e+11    393000.0  2411.042945   \n",
       "\n",
       "                                     texto_destacado  calidad_cocina  \\\n",
       "0                       Unico!!! Dúplex en Collblanc             1.0   \n",
       "1  Piso en venta con amplio balcón junto al CC Gr...             0.0   \n",
       "2                          TODO EXTERIOR Y REFORMADO             1.0   \n",
       "3                           Piso para entrar a vivir             1.0   \n",
       "4                     de obra nueva a estrenar. 4hab             1.0   \n",
       "\n",
       "   diseny_cocina  alta_calidad  reform_inmob  C_contempo  C_estado  \\\n",
       "0            0.0           0.0           0.0         1.0       1.0   \n",
       "1            0.0           1.0           0.0         1.0       2.0   \n",
       "2            0.0           1.0           1.0         0.0       1.0   \n",
       "3            0.0           0.0           1.0         1.0       2.0   \n",
       "4            1.0           0.0           1.0         1.0       2.0   \n",
       "\n",
       "   C_armarios  B_contempo  B_estado  B_lavamano  R_contempo  R_estado  \\\n",
       "0         1.0         1.0       1.0         0.0         1.0       1.0   \n",
       "1         0.0         1.0       1.0         0.0         1.0       1.0   \n",
       "2         1.0         0.0       1.0         0.0         1.0       2.0   \n",
       "3         1.0         0.0       1.0         0.0         0.0       1.0   \n",
       "4         1.0         1.0       2.0         1.0         1.0       2.0   \n",
       "\n",
       "   R_carpinte  R_singular  R_ventana  \n",
       "0         1.0         0.0        0.0  \n",
       "1         1.0         0.0        0.0  \n",
       "2         1.0         0.0        1.0  \n",
       "3         1.0         0.0        1.0  \n",
       "4         1.0         0.0        1.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hab=h[['OBJECTID_1', 'codigo_inmueble1', 'precio_eur', 'Unit_price', 'texto_destacado',\n",
    "         'calidad_cocina', 'diseny_cocina', 'alta_calidad', 'reform_inmob', 'C_contempo', 'C_estado',\n",
    "         'C_armarios', 'B_contempo', 'B_estado', 'B_lavamano', 'R_contempo', 'R_estado', \n",
    "         'R_carpinte', 'R_singular', 'R_ventana']]\n",
    "hab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c513936b-74e8-479d-9198-3d97e46c85e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID_1</th>\n",
       "      <th>codigo_inmueble1</th>\n",
       "      <th>precio_eur</th>\n",
       "      <th>Unit_price</th>\n",
       "      <th>texto_destacado</th>\n",
       "      <th>alta_calidad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.872004e+12</td>\n",
       "      <td>345000.0</td>\n",
       "      <td>4011.627907</td>\n",
       "      <td>Unico!!! Dúplex en Collblanc</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.020004e+12</td>\n",
       "      <td>370000.0</td>\n",
       "      <td>3814.432990</td>\n",
       "      <td>Piso en venta con amplio balcón junto al CC Gr...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>8.700366e+10</td>\n",
       "      <td>169000.0</td>\n",
       "      <td>2194.805195</td>\n",
       "      <td>TODO EXTERIOR Y REFORMADO</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.000037e+11</td>\n",
       "      <td>229000.0</td>\n",
       "      <td>2410.526316</td>\n",
       "      <td>Piso para entrar a vivir</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.380035e+11</td>\n",
       "      <td>393000.0</td>\n",
       "      <td>2411.042945</td>\n",
       "      <td>de obra nueva a estrenar. 4hab</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID_1  codigo_inmueble1  precio_eur   Unit_price  \\\n",
       "0         1.0      2.872004e+12    345000.0  4011.627907   \n",
       "1         2.0      5.020004e+12    370000.0  3814.432990   \n",
       "2         3.0      8.700366e+10    169000.0  2194.805195   \n",
       "3         4.0      5.000037e+11    229000.0  2410.526316   \n",
       "4         5.0      5.380035e+11    393000.0  2411.042945   \n",
       "\n",
       "                                     texto_destacado  alta_calidad  \n",
       "0                       Unico!!! Dúplex en Collblanc           0.0  \n",
       "1  Piso en venta con amplio balcón junto al CC Gr...           1.0  \n",
       "2                          TODO EXTERIOR Y REFORMADO           1.0  \n",
       "3                           Piso para entrar a vivir           0.0  \n",
       "4                     de obra nueva a estrenar. 4hab           0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "habit=hab[['OBJECTID_1', 'codigo_inmueble1', 'precio_eur', 'Unit_price', 'texto_destacado',\n",
    "         'alta_calidad']]\n",
    "habit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df8e5641-4eec-4f8b-94c4-2c6794663797",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4043 entries, 0 to 4042\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   OBJECTID_1        4043 non-null   float64\n",
      " 1   codigo_inmueble1  4043 non-null   float64\n",
      " 2   precio_eur        4043 non-null   float64\n",
      " 3   Unit_price        4043 non-null   float64\n",
      " 4   texto_destacado   4043 non-null   object \n",
      " 5   alta_calidad      4043 non-null   float64\n",
      "dtypes: float64(5), object(1)\n",
      "memory usage: 189.6+ KB\n"
     ]
    }
   ],
   "source": [
    "habit.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad8bf2b-4fc1-4b9b-92fa-f046c4f72f85",
   "metadata": {},
   "source": [
    "Una de las cosas a las que pueden ser sensibles este tipo de modelos es al desequilibrio entre las clases (por ejemplo, hay muchas más instancias de una clase que de la otra), de manera que su precisión puede ser alta incluso si el modelo predice incorrectamente la clase menos frecuente con frecuencia. Veamos cuántos 0 y 1 tenemos en la columna **alta_calidad**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2204cdc4-50b4-4baa-8e86-e0240deaca2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alta_calidad\n",
      "0.0    3208\n",
      "1.0     835\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "conteo = habit['alta_calidad'].value_counts()\n",
    "print(conteo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5bb4e3-6329-461b-8798-9f5521b64b48",
   "metadata": {
    "tags": []
   },
   "source": [
    "Vamos a tener que cuidar cómo se re-distribuyen estos valores cuando elija datos de entrenamiento y testeo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24d0fdd-27a4-4392-9f7e-461876e4fc02",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Elaboración del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f041129-912c-4ffc-ad18-7d33e889db30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 91.47%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(habit['texto_destacado'], habit['alta_calidad'], \n",
    "                                                    test_size=0.2, random_state=42) #Ojo: elijo 80-20.\n",
    "\n",
    "# Preprocesamiento y representación de texto\n",
    "custom_stopwords = ['de', 'la', 'el', 'los', 'las', 'en', 'para', 'con', 'y', 'o', 'un', 'una', 'que', 'se', 'su', 'sus']  # Agrega más palabras si es necesario\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=custom_stopwords)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Entrenar un modelo de clasificación (por ejemplo, SVM)\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predecir sobre los datos de prueba\n",
    "y_pred = svm_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluar el modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Exactitud del modelo: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff27daa-e7e5-433f-91ff-a7b25c12d0e9",
   "metadata": {},
   "source": [
    "Por si acaso contamos cómo se distribuyeron los 0 y 1 en los datos de entrenamiento. Vemos que es muy similar al dataset original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02dab152-4ef3-4ad9-b5ae-36aaeca4a7fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alta_calidad\n",
      "0.0    2573\n",
      "1.0     661\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "conteo2 = y_train.value_counts()\n",
    "print(conteo2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1a387b-7fb0-4f50-93a8-2afac5929205",
   "metadata": {},
   "source": [
    "Algunos indicadores adicionales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "616c319c-6592-4d70-a522-d2c6950286b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 0.8387096774193549\n",
      "Recall: 0.7471264367816092\n",
      "F1 Score: 0.790273556231003\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Calcular precision, recall y F1 sobre los datos de prueba\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Imprimir las métricas\n",
    "print(\"Precisión:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2532dbb8-1828-427f-a2ca-d09cbf2ae883",
   "metadata": {},
   "source": [
    "Algunos apuntes: \n",
    "\n",
    "- Precisión (Precision): La precisión se refiere a la proporción de las instancias clasificadas como positivas que son realmente positivas.Se calcula como el número de verdaderos positivos dividido por la suma de verdaderos positivos y falsos positivos. **Es útil cuando el costo de los falsos positivos es alto y deseas minimizarlos**.\n",
    "\n",
    "- Exactitud (Accuracy): La exactitud es la proporción de todas las predicciones que son correctas. Se calcula como la suma de verdaderos positivos y verdaderos negativos dividido por el total de instancias. Es una medida global del rendimiento del modelo y **es útil cuando todas las clases tienen una importancia similar**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a8ad60-92a4-4631-bd53-6ed0b68ff977",
   "metadata": {},
   "source": [
    "La precisión del modelo parece ser buena. Veamos qué pasa si comparamos los valores que predice con los valores reales del mismo dataset, pero esta vez completo (100%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a33ab0c5-ac01-40c4-ab10-69a42ff125ae",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      OBJECTID_1  codigo_inmueble1  precio_eur   Unit_price  \\\n",
      "0            1.0      2.872004e+12    345000.0  4011.627907   \n",
      "1            2.0      5.020004e+12    370000.0  3814.432990   \n",
      "2            3.0      8.700366e+10    169000.0  2194.805195   \n",
      "3            4.0      5.000037e+11    229000.0  2410.526316   \n",
      "4            5.0      5.380035e+11    393000.0  2411.042945   \n",
      "...          ...               ...         ...          ...   \n",
      "4038      4039.0      4.264900e+13    230000.0  4035.087719   \n",
      "4039      4040.0      4.300000e+13     80000.0  1777.777778   \n",
      "4040      4041.0      4.425000e+13    159900.0  2050.000000   \n",
      "4041      4042.0      4.425000e+13    179500.0  2564.285714   \n",
      "4042      4043.0      4.469700e+13    162000.0  2382.352941   \n",
      "\n",
      "                                        texto_destacado  alta_calidad  \\\n",
      "0                          Unico!!! Dúplex en Collblanc           0.0   \n",
      "1     Piso en venta con amplio balcón junto al CC Gr...           1.0   \n",
      "2                             TODO EXTERIOR Y REFORMADO           1.0   \n",
      "3                              Piso para entrar a vivir           0.0   \n",
      "4                        de obra nueva a estrenar. 4hab           0.0   \n",
      "...                                                 ...           ...   \n",
      "4038                                                              0.0   \n",
      "4039                               ACOGEDOR Y REFORMADO           1.0   \n",
      "4040     Piso con 3 habitaciones con aire acondicionado           0.0   \n",
      "4041                           Ático con 3 habitaciones           0.0   \n",
      "4042  Piso con 3 habitaciones con ascensor y calefac...           0.0   \n",
      "\n",
      "      alta_calidad_predicha  \n",
      "0                       0.0  \n",
      "1                       0.0  \n",
      "2                       0.0  \n",
      "3                       0.0  \n",
      "4                       0.0  \n",
      "...                     ...  \n",
      "4038                    0.0  \n",
      "4039                    0.0  \n",
      "4040                    0.0  \n",
      "4041                    0.0  \n",
      "4042                    0.0  \n",
      "\n",
      "[4043 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rojas\\AppData\\Local\\Temp\\ipykernel_35456\\425510422.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  habit['alta_calidad_predicha'] = y_train_pred.tolist() + y_test_pred.tolist()\n"
     ]
    }
   ],
   "source": [
    "# Predecir sobre los datos de entrenamiento y prueba\n",
    "y_train_pred = svm_model.predict(X_train_tfidf)\n",
    "y_test_pred = svm_model.predict(X_test_tfidf)\n",
    "\n",
    "# Añadir columnas al DataFrame con los valores predichos\n",
    "habit['alta_calidad_predicha'] = y_train_pred.tolist() + y_test_pred.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c9309d3-d909-46e4-ae64-07c6023ef584",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de valores coincidentes: 2775\n"
     ]
    }
   ],
   "source": [
    "# Contar valores coincidentes entre 'alta_calidad' y 'alta_calidad_predicha'\n",
    "coincidencias = (habit['alta_calidad'] == habit['alta_calidad_predicha']).sum()\n",
    "\n",
    "print(\"Cantidad de valores coincidentes:\", coincidencias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb1141ca-367c-4770-9215-aca9cced14c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6863715063071977"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2775/4043"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0393c67-e146-4c82-930b-526f85e55cc7",
   "metadata": {},
   "source": [
    "Sólo coincide en el 68%, pero veamos qué pasa cuando lo pasamos a otro dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10843153-6578-459e-b27e-06bec35037fa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Prueba del modelo (6k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765f1edf-7d71-4bd9-9f4c-37308db85163",
   "metadata": {},
   "source": [
    "Voy a probar el modelo con la base de datos que me compartió Paúl, que tiene casi 6k observaciones. Primero cargo los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3376d0fb-5416-4bd5-ad03-3163d05c2b5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5467 entries, 0 to 5466\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   codigo_inmueble1  5467 non-null   float64\n",
      " 1   precio_eur        5467 non-null   float64\n",
      " 2   Unit_price        5467 non-null   float64\n",
      " 3   texto_destacado   5467 non-null   object \n",
      " 4   alta_calidad      5467 non-null   float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 213.7+ KB\n"
     ]
    }
   ],
   "source": [
    "hab6=pd.read_spss('rawdata/BDD 10958 EPC and NO EPC - PEZ_2.sav')\n",
    "habit6=hab6[['codigo_inmueble1', 'precio_eur', 'Unit_price', 'texto_destacado',\n",
    "         'alta_calidad']]\n",
    "habit6.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d49570-a482-4736-8394-02fa1b349bb2",
   "metadata": {
    "tags": []
   },
   "source": [
    "Y ahora, con el modelo previamente entrenado, predigo los valores de calidad y los comparo con los valores reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e6b846a-3dcb-4bb6-9b9e-164d4fc52e5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de valores coincidentes: 4948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rojas\\AppData\\Local\\Temp\\ipykernel_35456\\1795496055.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  habit6['alta_calidad_predicha'] = y_habit6_pred\n"
     ]
    }
   ],
   "source": [
    "# Preprocesamiento del texto en 'texto_destacado' usando el mismo TfidfVectorizer\n",
    "X_habit6_tfidf = tfidf_vectorizer.transform(habit6['texto_destacado'])\n",
    "\n",
    "# Predecir la calidad de los inmuebles en 'habit6' utilizando el modelo ya entrenado\n",
    "y_habit6_pred = svm_model.predict(X_habit6_tfidf)\n",
    "\n",
    "# Agregar una columna 'alta_calidad_predicha' al DataFrame 'habit6' con las predicciones del modelo\n",
    "habit6['alta_calidad_predicha'] = y_habit6_pred\n",
    "\n",
    "coincidencias6 = (habit6['alta_calidad'] == habit6['alta_calidad_predicha']).sum()\n",
    "\n",
    "print(\"Cantidad de valores coincidentes:\", coincidencias6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d8a2ddc-4ab3-408b-b473-6bcd7d62fc7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9050667642216939"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4948/5467"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfcd6e0-456c-4313-9c92-2d6b428e50ad",
   "metadata": {},
   "source": [
    "Esta vez sí se acerca bastante al valor de exactitud que indicaba el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "baebf745-31f6-49e7-b044-77bfa5d3620f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/LLM1-SVM.joblib']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "dump(svm_model, 'modelos/LLM1-SVM.joblib')\n",
    "\n",
    "# Cargar el modelo entrenado\n",
    "#svm_model_cargado = load('modelo_svm.joblib')\n",
    "\n",
    "# Ahora puedes usar svm_model_cargado para hacer predicciones como lo harías con svm_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b2a137-bef5-4eed-a904-7c20a3f73541",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Segundo modelo (4k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d07f36-b153-45ad-bee7-64bf0cd76fe9",
   "metadata": {},
   "source": [
    "Esta vez usaremos una red neuronal con tres capas densas, cada una seguida de una capa de abandono (dropout) para evitar el sobreajuste. Utilizamos la función de activación 'relu' en las capas ocultas y 'sigmoid' en la capa de salida para problemas de clasificación binaria. El optimizador Adam se utiliza para minimizar la pérdida de entropía cruzada binaria, y la exactitud (*accuracy*) se utiliza como métrica de evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e0994bd-4336-464e-ae53-6198c5404146",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rojas\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\rojas\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\rojas\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rojas\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rojas\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rojas\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 2s 7ms/step - loss: 0.6758 - accuracy: 0.7365 - val_loss: 0.4593 - val_accuracy: 0.7849\n",
      "Epoch 2/10\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5219 - accuracy: 0.7870 - val_loss: 0.3740 - val_accuracy: 0.8232\n",
      "Epoch 3/10\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.3894 - accuracy: 0.8411 - val_loss: 0.3401 - val_accuracy: 0.8430\n",
      "Epoch 4/10\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2799 - accuracy: 0.8782 - val_loss: 0.3446 - val_accuracy: 0.8616\n",
      "Epoch 5/10\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2361 - accuracy: 0.9051 - val_loss: 0.3510 - val_accuracy: 0.8727\n",
      "Epoch 6/10\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1980 - accuracy: 0.9236 - val_loss: 0.3701 - val_accuracy: 0.8789\n",
      "Epoch 7/10\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1543 - accuracy: 0.9378 - val_loss: 0.3885 - val_accuracy: 0.8789\n",
      "Epoch 8/10\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1517 - accuracy: 0.9416 - val_loss: 0.4088 - val_accuracy: 0.8752\n",
      "Epoch 9/10\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1249 - accuracy: 0.9536 - val_loss: 0.4297 - val_accuracy: 0.8813\n",
      "Epoch 10/10\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1216 - accuracy: 0.9539 - val_loss: 0.4535 - val_accuracy: 0.8702\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.8702\n",
      "Precisión del modelo en los datos de prueba: 0.8702101111412048\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "##### Esto ya lo tengo del modelo anterior, por eso no lo ejecuto\n",
    "# Dividir los datos en características (X) y etiquetas (y)\n",
    "#X = habit['texto_destacado']\n",
    "#y = habit['alta_calidad']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Representación TF-IDF de las características de texto\n",
    "#tfidf_vectorizer = TfidfVectorizer(stop_words=custom_stopwords)\n",
    "#X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "#X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "##### A partir de aquí ya son cosas nuevas para este modelo de redes neuronales\n",
    "# Escalar las características numéricas\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_tfidf.toarray())\n",
    "X_test_scaled = scaler.transform(X_test_tfidf.toarray())\n",
    "\n",
    "# Crear el modelo de redes neuronales\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid') #Sigmoid es más adecuado para variables binarias\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_data=(X_test_scaled, y_test))\n",
    "\n",
    "# Evaluar el modelo en los datos de prueba\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Exactitud del modelo en los datos de prueba:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2430fe-ea03-4573-99ca-25cd03078a8f",
   "metadata": {},
   "source": [
    "Exactitud ligeramente menor que el modelo anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "457363cd-109f-452a-9494-a7ae85567660",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 2ms/step\n",
      "Accuracy: 0.8702101359703337\n",
      "Recall: 0.6436781609195402\n",
      "Precision: 0.7225806451612903\n",
      "F1 Score: 0.6808510638297872\n",
      "Confusion Matrix:\n",
      " [[592  43]\n",
      " [ 62 112]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "\n",
    "# Calcular las predicciones binarias del modelo en el conjunto de datos de prueba\n",
    "umbral = 0.5  # Umbral para convertir las probabilidades en etiquetas binarias\n",
    "y_pred_binario = [1 if pred >= umbral else 0 for pred in model.predict(X_test_scaled)]\n",
    "\n",
    "# Calcular las métricas de evaluación\n",
    "accuracy = accuracy_score(y_test, y_pred_binario)\n",
    "recall = recall_score(y_test, y_pred_binario)\n",
    "precision = precision_score(y_test, y_pred_binario)\n",
    "f1 = f1_score(y_test, y_pred_binario)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_binario)\n",
    "\n",
    "# Imprimir las métricas\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c2cc10-d03e-48f6-8feb-1e2cc8434b4d",
   "metadata": {},
   "source": [
    "- Precisión (Accuracy):\n",
    "    - La precisión es la proporción de predicciones correctas sobre el total de predicciones.\n",
    "    - Una precisión del 1.0 indica que todas las predicciones son correctas, mientras que una precisión del 0.0 indica que ninguna predicción es correcta.\n",
    "    - Es una métrica general del rendimiento del modelo, pero puede ser engañosa si hay un desequilibrio en las clases objetivo.\n",
    "\n",
    "- Recall (Exhaustividad):\n",
    "    - La exhaustividad es la proporción de positivos reales que se identificaron correctamente.\n",
    "    - Una exhaustividad del 1.0 indica que todas las instancias positivas se han identificado correctamente, mientras que una exhaustividad del 0.0 indica que ninguna instancia positiva se ha identificado correctamente.\n",
    "    - Es útil cuando la identificación de instancias positivas es crítica y no se pueden permitir falsos negativos.\n",
    "\n",
    "- Precisión (Precision):\n",
    "    - La precisión es la proporción de instancias positivas predichas que fueron correctamente identificadas.\n",
    "    - Una precisión del 1.0 indica que todas las instancias predichas como positivas son verdaderas positivas, mientras que una precisión del 0.0 indica que ninguna instancia predicha como positiva es realmente positiva.\n",
    "    - Es útil cuando es importante evitar falsos positivos.\n",
    "\n",
    "- F1 Score:\n",
    "    - El puntaje F1 es la media armónica de precisión y exhaustividad.\n",
    "    - Proporciona un equilibrio entre precisión y exhaustividad, lo que lo hace útil cuando se desea tener un buen rendimiento en ambas métricas.\n",
    "    - Un puntaje F1 del 1.0 indica un equilibrio perfecto entre precisión y exhaustividad.\n",
    "\n",
    "- Matriz de Confusión:\n",
    "    - La matriz de confusión es una tabla que describe la calidad de las predicciones del modelo.\n",
    "    - Proporciona una descripción detallada de los resultados de clasificación, mostrando el número de verdaderos positivos, verdaderos negativos, falsos positivos y falsos negativos.\n",
    "    - Es útil para identificar dónde el modelo está cometiendo errores y para evaluar el desempeño en cada clase por separado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2328d2f5-8951-40f2-84ca-e27eb8e62e77",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Prueba del modelo (6K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bef2ea06-88fc-4994-af55-210723fbb2d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 1s 2ms/step\n",
      "Cantidad de valores coincidentes: 4869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rojas\\AppData\\Local\\Temp\\ipykernel_35456\\1738249818.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  habit6['acp-LLM-ANN'] = acp_LLM_ANN\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Preprocesamiento del texto en 'texto_destacado' utilizando el mismo TfidfVectorizer y StandardScaler\n",
    "#X_habit6_tfidf = tfidf_vectorizer.transform(habit6['texto_destacado']) #### Esto ya no lo ejecuto porque ya lo hice con el modelo anterior\n",
    "X_habit6_scaled = scaler.transform(X_habit6_tfidf.toarray())\n",
    "\n",
    "#### A partir de aquí ya es nuevo\n",
    "# Predecir la calidad de los inmuebles en 'habit6' utilizando el modelo de redes neuronales ya entrenado\n",
    "y_habit6_pred = model.predict(X_habit6_scaled)\n",
    "\n",
    "# Convertir las predicciones a etiquetas binarias (0 o 1) utilizando un umbral (por ejemplo, 0.5)\n",
    "umbral = 0.5\n",
    "acp_LLM_ANN = [1 if pred >= umbral else 0 for pred in y_habit6_pred] #acp de alta_calidad_predicha\n",
    "\n",
    "# Agregar una columna 'alta_calidad_predicha' al DataFrame 'habit6' con las predicciones del modelo\n",
    "habit6['acp-LLM-ANN'] = acp_LLM_ANN\n",
    "\n",
    "#coincidencias6 = (habit6['alta_calidad'] == habit6['acp-LLM-ANN']).sum()\n",
    "\n",
    "print(\"Cantidad de valores coincidentes:\", (habit6['alta_calidad'] == habit6['acp-LLM-ANN']).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc2ab4d1-6903-4952-ab4b-82a9f5e5e12f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8906164258276934"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4869/5467"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d14bf1-7b6d-45b3-9610-2116c9399015",
   "metadata": {},
   "source": [
    "Parece tener un rendimiento ligeramente menor que el **modelo SVM**. Guardamos los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "422744e6-003c-4bd2-9083-dea025c3752a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: modelos/LLM1-ANN\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: modelos/LLM1-ANN\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['modelos/LLM1-ANN/history.joblib']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardar el modelo entrenado\n",
    "model.save('modelos/LLM1-ANN')\n",
    "\n",
    "# Guardar el historial de entrenamiento\n",
    "dump(history, 'modelos/LLM1-ANN/history.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2811e9a2-f670-4daf-8efc-873c842c8e2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tercer modelo (4k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "44ccf4ec-4154-4f1d-9675-596bb4a03ad3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9048207663782447\n",
      "Recall: 0.6954022988505747\n",
      "Precision: 0.8344827586206897\n",
      "F1 Score: 0.7586206896551724\n",
      "Confusion Matrix:\n",
      " [[611  24]\n",
      " [ 53 121]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "\n",
    "#### Esto ya lo tengo\n",
    "\n",
    "# Dividir los datos en características (X) y etiquetas (y)\n",
    "#X = habit['texto_destacado']\n",
    "#y = habit['alta_calidad']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Representación TF-IDF de las características de texto\n",
    "#tfidf_vectorizer = TfidfVectorizer(stop_words=custom_stopwords)\n",
    "#X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "#X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "#### Esto ya es nuevo\n",
    "# Crear y entrenar el modelo de Random Forest\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predecir las etiquetas en el conjunto de prueba\n",
    "y_pred = random_forest.predict(X_test_tfidf)\n",
    "\n",
    "# Calcular las métricas de evaluación\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Imprimir las métricas\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9a5681-025a-41f1-8d29-bdeedf34ae32",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prueba del modelo (6k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bc65f088-b4b2-461e-8bc0-e73ec8c55ff8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de valores coincidentes: 5045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rojas\\AppData\\Local\\Temp\\ipykernel_35456\\1587127615.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  habit6['acp-LLM-RF'] = random_forest.predict(X_habit6_tfidf)\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Representación TF-IDF de las características de texto\n",
    "#tfidf_vectorizer = TfidfVectorizer(stop_words=custom_stopwords)\n",
    "#X_habit6_tfidf = tfidf_vectorizer.fit_transform(habit6['texto_destacado'])\n",
    "\n",
    "# Predecir las etiquetas en el conjunto de datos habit6\n",
    "habit6['acp-LLM-RF'] = random_forest.predict(X_habit6_tfidf)\n",
    "\n",
    "print(\"Cantidad de valores coincidentes:\", (habit6['alta_calidad'] == habit6['acp-LLM-RF']).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3bae34d5-3c7b-4420-b908-a880c12bdcba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9228095847814157"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5045/5467"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb81a6f-0eac-499b-8a9d-6419e36255f4",
   "metadata": {},
   "source": [
    "De momento, el mejor modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a3f5ecb2-af16-4fe0-a588-3ba8cec4e31c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/LLM1-RF.joblib']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from joblib import dump #Ya lo había cargado antes\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "dump(random_forest, 'modelos/LLM1-RF.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca10973d-e467-451f-9cd9-eb4fa5d2abcd",
   "metadata": {},
   "source": [
    "Lo que puedo hacer es trabajar con una BBDD más grande: Pedir al CPSV los datasets con datos sobre calidad arquitectónica de todos los años, juntarlos, y con eso entrenar un nuevo modelo más grande.\n",
    "\n",
    "La otra opción, más tediosa, es utilizar un LLM pre-entrenado y hacerle fine tuning con mis datos, pero eso aún no he descubierto como hacerlo bien."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
