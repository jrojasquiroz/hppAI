{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41a4bd8c-7e22-4025-a65b-a23e84c3f9e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. SVM (6k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215e576b-a4ba-4bb4-abae-b2f0a7cfa54d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1. Revisión de la base de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991574c9-a523-4190-80e1-9e305e832e5d",
   "metadata": {},
   "source": [
    "Con la BBDD que me compartió Paúl, voy a crear un modelo que, a partir de un indicador de calidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ecd57bb-d2d8-4b96-a1e6-3a6360888ac1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyreadstat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec26856-7564-45c8-a901-ef3120450792",
   "metadata": {},
   "source": [
    "Importamos el archivo, revisamos las columnas, nos quedamos sólo con las que nos interesan y vemos cuántas filas tenemos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08216e5b-ee94-4028-a074-0033a6f732a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "h=pd.read_spss('rawdata/BDD 10958 EPC and NO EPC - PEZ_2.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dcf9ace-6302-4476-95b1-a6e67b88d0a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OBJECTID', 'codigo_inmueble1', 'Title', 'Type_build', 'Type_opera', 'Link', 'Location', 'Lat_X', 'Lon_Y', 'Climatic_Z', 'Nom_Mun', 'precio_eur', 'superficie', 'superficie2', 'Unit_price', 'Ln_total_pr', 'Ln_unit_pr', 'numero_habitaciones', 'numero_bano', 'ratio_bano_hab', 'numero_aseo', 'ascensor', 'interac_planta', 'numero_de_piso', 'anyo_constr_ponderad', 'antig_ponderad', 'Inverse_Age', 'Year_Before_1981', 'Year_1982_2006', 'Year_After_2007', 'superficie_terraza_m2', 'grand_terr_20m2', 'superficie_jardin_m2', 'superficie_salon', 'bool_despacho', 'bool_buhardilla', 'bool_trastero', 'bool_lavadero', 'bool_piscina_comunitaria', 'bool_jardin_comunitario', 'bool_amueblado', 'bool_ascensor', 'descripcion', 'bool_aire_acondicionado', 'bool_calefaccion', 'bool_chimenea', 'texto_destacado', 'Description', 'calificacion_consumo_letra', 'calificacion_consumo_valor', 'calificacion_emision_letra', 'calificacion_emision_valor', 'Dum_EPC', 'EPC_A_emision', 'EPC_B_emision', 'EPC_C_emision', 'EPC_D_emision', 'EPC_E_emision', 'EPC_F_emision', 'EPC_G_emision', 'COD_MUN', 'temp_enero', 'temp_julio', 'radiacion_enero', 'radiacion_julio', 'POB_91', 'POB_01', 'POB_06', 'POR_01', 'LTL1991_M', 'LTL_2001', 'DLTL_MUN', 'RW', 'FLE', 'FLS', 'SUP_URB_90', 'SUP_URB_00', 'Job_ratio_01', 'Autocontencion_01', 'Nodalidad_01', 'Dist_CBD2', 'Dist_sub_center', 'Elevation_Mean', 'dum_acces_viappal', 'IND_pr', 'FIRE_pr', 'Div_LandUse', 'COD_SEC', 'pr_directivo', 'pr_tecnico_prof', 'pr_tecnico_apoyo', 'pr_empl_admin', 'pr_restaur_comer', 'pr_agri_calificado', 'pr_artesano', 'pr_operador', 'pr_no_calif', 'desplaz_ponderado', 'plant_ras_pond', 'edif_ruin_pr', 'edif_malo_pr', 'edif_deficient_pr', 'edif_bueno_pr', 'Doorman_pr', 'opin_ruido_si_pr', 'opin_contam_si_pr', 'opin_calle_sucia_pr', 'opin_mala_comunic_pr', 'opin_pocazonaverde_pr', 'opin_delincuencia_pr', 'opin_falta_aseo_pr', 'local_salud_pr', 'local_edu_pr', 'local_social_pr', 'local_cult_pr', 'local_comerc_pr', 'local_oficinas_pr', 'local_industr_pr', 'local_agrar_pr', 'POB_TOTAL', 'POB_RESID', 'LOC_TOTAL', 'POR_TOTAL', 'LOC_VIV_TOTAL', 'dens_loc_100hab', 'dens_loc_sup', 'dens_pob_sup', 'estud_sin_pr', 'estud_primer_pr', 'estud_segund_pr', 'estud_tercer_pr', 'VIV_ppales_TOTAL', 'Sup_viv_sec', 'viv_ppales_pr', 'viv_no_ppales_pr', 'viv_secundarias_pr', 'viv_vacias_pr', 'viv_unifam_pr', 'viv_aptos_pr', 'resi_euro_pr', 'resi_africa_pr', 'resi_america_pr', 'resi_asia_pr', 'resi_oceania_pr', 'H_ocup_POR', 'H_loc_INE', 'H_tamaviv', 'H_ocup_POR_Xpor', 'H_loc_INE_XLOCS', 'H_tamaviv_Xvivs', 'CT_renta_alta_CPA', 'CT_renta_meda_CPA', 'CT_renta_medb_CPA', 'Income_Household_2016', 'DP2e', 'Dens_Time_total', 'Dens_Time_total_work', 'Dens_Time_total_Nwork', 'Dens_pers_act_total', 'Dens_pers_act_working', 'Dens_pers_act_Nworking', 'Div_total_work', 'Div_act_work', 'Div_socio_work', 'Div_total_Nwork', 'Div_act_Nwork', 'Div_socio_Nwork', 'calidad_cocina', 'diseny_cocina', 'alta_calidad', 'reform_inmob', 'dum_mar_200m', 'dum_ttpp_riel_urb', 'dist_near_riel_km', 'dist_near_viappal_km', 'C_contempo', 'C_estado', 'C_armarios', 'B_contempo', 'B_estado', 'B_lavamano', 'R_contempo', 'R_estado', 'R_carpinte', 'R_singular', 'R_ventana', 'Dum_precio', 'Precio_red', 'scrap_year', 'persona', 'Y_2023', 'Filtro', 'filter_$', 'EPC_AB', 'EPC_ABC', 'EPC_ORD', 'Contempo_all', 'Closets_all', 'Contempo_seg', 'Conservation_seg', 'MAH_1', 'MAH_2', 'FAC1_1', 'FAC2_1', 'FAC3_1', 'FAC4_1', 'FAC5_1', 'FAC6_1', 'FAC7_1', 'QCL_1', 'EPC_A_emission_2023', 'EPC_B_emission_2023', 'EPC_C_emission_2023', 'EPC_D_emission_2023', 'EPC_E_emission_2023', 'EPC_F_emission_2023', 'EPC_G_emission_2023', 'EPC_AB_2023', 'EPC_ABC_2023', 'Cluster_1', 'Cluster_2', 'Cluster_3', 'EPC_ABC_2023_CL1', 'EPC_ABC_2023_CL2', 'EPC_ABC_2023_CL3', 'EPC_ABC_CL3', 'EPC_ABC_CL2', 'EPC_ABC_CL1', 'IMR', 'Dist_CBD2_2023', 'Dist_sub_center_2023', 'DP2e_2023', 'Dummie_Terraza', 'Dummie_Terraza_2023', 'Inv_sup_terraza', 'Inv_sup_terraza_2023', 'Bool_piscina_comunitaria_2023', 'Contempo_PC_seg_2023', 'Conservation_PC_seg_2023', 'viv_aptos_pr_2023', 'Div_landUse_2023', 'Inverse_Age_2023', 'desplaz_ponderado_2023', 'Ratio_bano_hab_2023', 'Superficie_2023', 'bool_calefacción_2023', 'bool_aire_acondicionado_2023', 'interac_planta_2023', 'bool_trastero_2023', 'ascensor_2023', 'Precio_red_2023', 'grand_terr_20m2_2023', 'dum_mar200m_2023', 'Income_household_2016_2023', 'CT_renta_alta_2023', 'CT_renta_meda_2023', 'Inv_dist_sub_center', 'Inv_dist_sub_center_2023', 'emp_2020', 'emp_2022', 'Tevolu_20_23', 'Tevolu_2023', 'dum_cercanies', 'dum_cercanies_2023', 'cercanies_CBD_2023', 'AUTOP_NEAR', 'PEAJE_2020', 'PEAJE_2023', 'peaje_cambio', 'dummy_sub_center', 'pobxdum_sub_center', 'pobxdist_sub_center', 'near_sub_centerp', 'Inv_near_sub_centerp', 'NEARsub_km', 'Inv_NEARsub_km', 'dum_sub_center', 'dum_sub_center_MOD', 'poblaxdum_sub_center', 'poblaxdum_sub_center_2023', 'poblaxnear_sub_center']\n"
     ]
    }
   ],
   "source": [
    "print(h.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089fd206-7029-4718-a0dc-3541f8468034",
   "metadata": {},
   "source": [
    "Voy a buscar cuáles son dummies. De acuerdo con el diccionario, *alta_calidad* es la que sintetiza la calidad del inmueble. Con ella trabajaré."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f5b78b6-91c7-4659-9c6b-f3e8deaaa74f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Type_build', 'Type_opera', 'numero_aseo', 'ascensor',\n",
       "       'Year_Before_1981', 'Year_1982_2006', 'Year_After_2007',\n",
       "       'grand_terr_20m2', 'bool_despacho', 'bool_buhardilla', 'bool_trastero',\n",
       "       'bool_lavadero', 'bool_piscina_comunitaria', 'bool_jardin_comunitario',\n",
       "       'bool_amueblado', 'bool_ascensor', 'bool_aire_acondicionado',\n",
       "       'bool_calefaccion', 'bool_chimenea', 'Dum_EPC', 'EPC_A_emision',\n",
       "       'EPC_B_emision', 'EPC_C_emision', 'EPC_D_emision', 'EPC_E_emision',\n",
       "       'EPC_F_emision', 'EPC_G_emision', 'dum_acces_viappal', 'calidad_cocina',\n",
       "       'diseny_cocina', 'alta_calidad', 'reform_inmob', 'dum_mar_200m',\n",
       "       'dum_ttpp_riel_urb', 'C_contempo', 'C_estado', 'C_armarios',\n",
       "       'B_contempo', 'B_estado', 'B_lavamano', 'R_contempo', 'R_estado',\n",
       "       'R_carpinte', 'R_singular', 'R_ventana', 'Dum_precio', 'scrap_year',\n",
       "       'Y_2023', 'Filtro', 'filter_$', 'EPC_AB', 'EPC_ABC', 'QCL_1',\n",
       "       'EPC_A_emission_2023', 'EPC_B_emission_2023', 'EPC_C_emission_2023',\n",
       "       'EPC_D_emission_2023', 'EPC_E_emission_2023', 'EPC_F_emission_2023',\n",
       "       'EPC_G_emission_2023', 'EPC_AB_2023', 'EPC_ABC_2023', 'Cluster_1',\n",
       "       'Cluster_2', 'Cluster_3', 'EPC_ABC_2023_CL1', 'EPC_ABC_2023_CL2',\n",
       "       'EPC_ABC_2023_CL3', 'EPC_ABC_CL3', 'EPC_ABC_CL2', 'EPC_ABC_CL1',\n",
       "       'Dummie_Terraza', 'Dummie_Terraza_2023',\n",
       "       'Bool_piscina_comunitaria_2023', 'bool_calefacción_2023',\n",
       "       'bool_aire_acondicionado_2023', 'bool_trastero_2023', 'ascensor_2023',\n",
       "       'grand_terr_20m2_2023', 'dum_mar200m_2023', 'dum_cercanies',\n",
       "       'dum_cercanies_2023', 'PEAJE_2020', 'PEAJE_2023', 'peaje_cambio',\n",
       "       'dummy_sub_center', 'dum_sub_center', 'dum_sub_center_MOD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_counts = h.nunique()\n",
    "categoricas = unique_counts[unique_counts < 5].index\n",
    "categoricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7c2561-33ef-4c1a-bf09-0bb0743c79ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "Ahora voy a buscar qué columnas tienen valores *string*, es decir, letras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a41a16ac-2559-4693-98ce-cbe81a38fa21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Title', 'Type_build', 'Type_opera', 'Link', 'Location', 'Climatic_Z',\n",
      "       'Nom_Mun', 'descripcion', 'texto_destacado', 'Description',\n",
      "       'calificacion_consumo_letra', 'calificacion_emision_letra', 'persona',\n",
      "       'AUTOP_NEAR'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "colstring = h.select_dtypes(include=['object'])\n",
    "print(colstring.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbddcf00-5d36-4119-94f3-03b0727c9ac9",
   "metadata": {},
   "source": [
    "Reviso a mayor profundidad qué información tienen aquellas que, creo, pueden acercarme a saber el anuncio de venta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b18d883-11b7-4c22-9ed5-a37db334aeb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto_destacado</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4 habitaciones en 11 de setembre</td>\n",
       "      <td>Piso reformado de 4 habitaciones, salón comedo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PIS BENET MATEU/ MANUEL DE FALLA</td>\n",
       "      <td>BENET MATEU, PIS D´ORIGEN AMB MOLT BONA DISTRI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apartamento tipo casa Canyelles</td>\n",
       "      <td>Apartamento pero con acceso independiente desd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TODO EXTERIOR Y REFORMADO</td>\n",
       "      <td>[A2977]PISAZO, EL MEJOR DE LA ZONA.FENOMENAL P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102 M2 EXTERIORES CON ASCENSOR</td>\n",
       "      <td>[A3001]VIVIENDA EN LA CALLE GARROFER DE SANT I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5462</th>\n",
       "      <td>Piso en venta en Can Pantiquet-Riera Seca</td>\n",
       "      <td>Piso En Mollet Del Vallès!Ubicado a 600m de la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5463</th>\n",
       "      <td>BUENA UBICACIÓN!</td>\n",
       "      <td>La Casa Agency presenta en Exclusividad, esta ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5464</th>\n",
       "      <td>PISO EN PLANTA BAJA CON PATIO DE 60m²</td>\n",
       "      <td>Mis Finques promociona esta planta baja con pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5465</th>\n",
       "      <td>PISO CON TERRAZA</td>\n",
       "      <td>PISO CON TERRAZAPiso con TERRAZA DE 40M2. La v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5466</th>\n",
       "      <td>Apartamento con 3 habitaciones con ascensor, p...</td>\n",
       "      <td>Precioso piso en una finca joven de tan solo 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5467 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        texto_destacado  \\\n",
       "0                      4 habitaciones en 11 de setembre   \n",
       "1                      PIS BENET MATEU/ MANUEL DE FALLA   \n",
       "2                       Apartamento tipo casa Canyelles   \n",
       "3                             TODO EXTERIOR Y REFORMADO   \n",
       "4                        102 M2 EXTERIORES CON ASCENSOR   \n",
       "...                                                 ...   \n",
       "5462          Piso en venta en Can Pantiquet-Riera Seca   \n",
       "5463                                   BUENA UBICACIÓN!   \n",
       "5464              PISO EN PLANTA BAJA CON PATIO DE 60m²   \n",
       "5465                                   PISO CON TERRAZA   \n",
       "5466  Apartamento con 3 habitaciones con ascensor, p...   \n",
       "\n",
       "                                            Description  \n",
       "0     Piso reformado de 4 habitaciones, salón comedo...  \n",
       "1     BENET MATEU, PIS D´ORIGEN AMB MOLT BONA DISTRI...  \n",
       "2     Apartamento pero con acceso independiente desd...  \n",
       "3     [A2977]PISAZO, EL MEJOR DE LA ZONA.FENOMENAL P...  \n",
       "4     [A3001]VIVIENDA EN LA CALLE GARROFER DE SANT I...  \n",
       "...                                                 ...  \n",
       "5462  Piso En Mollet Del Vallès!Ubicado a 600m de la...  \n",
       "5463  La Casa Agency presenta en Exclusividad, esta ...  \n",
       "5464  Mis Finques promociona esta planta baja con pa...  \n",
       "5465  PISO CON TERRAZAPiso con TERRAZA DE 40M2. La v...  \n",
       "5466  Precioso piso en una finca joven de tan solo 1...  \n",
       "\n",
       "[5467 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colstring[['texto_destacado','Description']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da6ff62-b2ca-4460-864b-7a099e8844a8",
   "metadata": {},
   "source": [
    "Ahora que ya sé qué columnas me interesan, las selecciono y empiezo a trabajar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb6a62b4-a674-4aa5-8b04-54c854827933",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5467 entries, 0 to 5466\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Description   5467 non-null   object \n",
      " 1   alta_calidad  5467 non-null   float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 85.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>alta_calidad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Piso reformado de 4 habitaciones, salón comedo...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BENET MATEU, PIS D´ORIGEN AMB MOLT BONA DISTRI...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apartamento pero con acceso independiente desd...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[A2977]PISAZO, EL MEJOR DE LA ZONA.FENOMENAL P...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[A3001]VIVIENDA EN LA CALLE GARROFER DE SANT I...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Description  alta_calidad\n",
       "0  Piso reformado de 4 habitaciones, salón comedo...           0.0\n",
       "1  BENET MATEU, PIS D´ORIGEN AMB MOLT BONA DISTRI...           0.0\n",
       "2  Apartamento pero con acceso independiente desd...           0.0\n",
       "3  [A2977]PISAZO, EL MEJOR DE LA ZONA.FENOMENAL P...           1.0\n",
       "4  [A3001]VIVIENDA EN LA CALLE GARROFER DE SANT I...           1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hab=h[['Description','alta_calidad']]\n",
    "hab.info()\n",
    "hab.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad8bf2b-4fc1-4b9b-92fa-f046c4f72f85",
   "metadata": {},
   "source": [
    "Una de las cosas a las que pueden ser sensibles este tipo de modelos es al desequilibrio entre las clases (por ejemplo, hay muchas más instancias de una clase que de la otra), de manera que su precisión puede ser alta incluso si el modelo predice incorrectamente la clase menos frecuente con frecuencia. Veamos cuántos 0 y 1 tenemos en la columna **alta_calidad**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2204cdc4-50b4-4baa-8e86-e0240deaca2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alta_calidad\n",
      "0.0    4458\n",
      "1.0    1009\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "conteo = hab['alta_calidad'].value_counts()\n",
    "print(conteo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5bb4e3-6329-461b-8798-9f5521b64b48",
   "metadata": {
    "tags": []
   },
   "source": [
    "Vamos a tener que cuidar cómo se re-distribuyen estos valores cuando elija datos de entrenamiento y testeo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24d0fdd-27a4-4392-9f7e-461876e4fc02",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.2. Elaboración del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcb075c8-6feb-4985-8bb7-bcdc0dc9911a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rojas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\rojas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import unicodedata\n",
    "\n",
    "# Descargar recursos necesarios para NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Definir función para lematización\n",
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "# Definir función para eliminar tildes y convertir a minúsculas\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convertir a minúsculas\n",
    "    text = ''.join(char for char in unicodedata.normalize('NFD', text) if unicodedata.category(char) != 'Mn')  # Eliminar tildes\n",
    "    return text\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(hab['Description'], hab['alta_calidad'], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42) #Ojo: elijo 80-20.\n",
    "\n",
    "# Preprocesamiento y representación de texto\n",
    "custom_stopwords = ['de', 'la', 'el', 'los', 'las', 'en', 'para', 'por',\n",
    "                    'con', 'y', 'o', 'un', 'una', 'que', 'se', 'su', 'sus']  # Agrega más palabras si es necesario\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=custom_stopwords)\n",
    "\n",
    "# Lematizar y preprocesar el texto\n",
    "X_train_lemmatized = X_train.apply(lemmatize_text)\n",
    "X_test_preprocessed = X_test.apply(preprocess_text)\n",
    "X_test_lemmatized = X_test_preprocessed.apply(lemmatize_text)\n",
    "\n",
    "# Entrenar el vectorizador TF-IDF\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_lemmatized)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test_lemmatized)\n",
    "\n",
    "# Obtener nombres de características y mapearlos a sus índices\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "feature_index_map = {word: idx for idx, word in enumerate(feature_names)}\n",
    "\n",
    "# Definir diccionario de palabras y factores de multiplicación de peso (eliminando tildes)\n",
    "word_weight_dict = {'noble': 1.5, 'reformado': 1.5, 'rehabilitado': 1.5, 'amplio': 1.5, \n",
    "                    'equipado': 1.5, 'restaurada': 1.5, 'isla': 1.5, 'isleta': 1.5, 'estrenar': 1.5,\n",
    "                    'conservado': 1.5, 'moderna': 1.5, 'acondicion': 1.5, 'lujo': 1.5, 'muy': 1.5,\n",
    "                    'diseno': 1.5, 'estado': 1.5, 'grand': 1.5, 'excelente': 1.5, 'vitroceramica': 1.5,\n",
    "                    'renovado': 1.5, 'impecable': 1.5, 'nuevo': 1.5, 'perfecto': 1.5, 'totalmente': 1.5,\n",
    "                    'total': 1.5, 'full': 1.5, 'espectacular': 1.5, 'maravillosa': 1.5, 'estupendo': 1.5,\n",
    "                    'optimo': 1.5, 'magnifica': 1.5, 'ideal': 1.5, 'fantastica': 1.5, 'vanguardia': 1.5,\n",
    "                    'office': 1.5, 'americana': 1.5, 'abierto': 1.5, 'vistas': 1.5, 'luminoso': 1.5,\n",
    "                    'iluminada': 1.5, 'bien': 1.5, 'entrar': 1.5, 'actualizado': 1.5, 'conservacion': 1.5,\n",
    "                    'buen': 1.5, 'condicion': 1.5, 'mantenida': 1.5, 'cuidado': 1.5, 'precioso': 1.5,\n",
    "                    'bonita': 1.5, 'encanto': 1.5, 'magnifica/co': 1.5, 'senoral': 1.5, 'vista': 1.5,\n",
    "                    'panoramico': 1.5, 'exterior': 1.5, 'modernista': 1.5, 'acogedora': 1.5, 'regia': 1.5,\n",
    "                    'gusto': 1.5, 'noucentista': 1.5, 'exclusivo': 1.5, 'neo-clasica': 1.5,\n",
    "                    'neoclasica': 1.5, 'inmejorable': 1.5, 'fabuloso': 1.5, 'majestuosa': 1.5,\n",
    "                    'alta calidad': 1.5, 'alto standing': 1.5, 'super': 1.5, 'impresionante': 1.5,\n",
    "                    'elegante': 1.5, 'esplendido': 1.5, 'calida': 1.5, 'especial': 1.5}\n",
    "\n",
    "# Modificar pesos según el diccionario\n",
    "for word, weight_factor in word_weight_dict.items():\n",
    "    word_no_accents = preprocess_text(word)\n",
    "    if word_no_accents in feature_index_map:\n",
    "        word_index = feature_index_map[word_no_accents]\n",
    "        X_train_tfidf[:, word_index] *= weight_factor\n",
    "        X_test_tfidf[:, word_index] *= weight_factor\n",
    "\n",
    "# Entrenar un modelo de clasificación (por ejemplo, SVM)\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b1718a4-ea6b-403a-b0bf-904dc57669ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6666666666666666\n",
      "Recall: 0.05102040816326531\n",
      "F1 Score: 0.0947867298578199\n",
      "Exactitud del modelo: 0.8254113345521024\n",
      "Confusion Matrix:\n",
      " [[893   5]\n",
      " [186  10]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "\n",
    "# Predecir sobre los datos de prueba\n",
    "y_predSVM = svm_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluar el modelo\n",
    "accuracySVM = accuracy_score(y_test, y_predSVM)\n",
    "\n",
    "# Calcular precision, recall y F1 sobre los datos de prueba\n",
    "precisionSVM = precision_score(y_test, y_predSVM)\n",
    "recallSVM = recall_score(y_test, y_predSVM)\n",
    "f1SVM = f1_score(y_test, y_predSVM)\n",
    "conf_matrixSVM = confusion_matrix(y_test, y_predSVM)\n",
    "\n",
    "# Imprimir las métricas\n",
    "print(\"Precision:\", precisionSVM)\n",
    "print(\"Recall:\", recallSVM)\n",
    "print(\"F1 Score:\", f1SVM)\n",
    "print(\"Exactitud del modelo:\", accuracySVM)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrixSVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2532dbb8-1828-427f-a2ca-d09cbf2ae883",
   "metadata": {},
   "source": [
    "Algunos apuntes: \n",
    "\n",
    "- Precisión (Precision): La precisión se refiere a la proporción de las instancias clasificadas como positivas que son realmente positivas.Se calcula como el número de verdaderos positivos dividido por la suma de verdaderos positivos y falsos positivos. **Es útil cuando el costo de los falsos positivos es alto y deseas minimizarlos**.\n",
    "\n",
    "- Exactitud (Accuracy): La exactitud es la proporción de todas las predicciones que son correctas. Se calcula como la suma de verdaderos positivos y verdaderos negativos dividido por el total de instancias. Es una medida global del rendimiento del modelo y **es útil cuando todas las clases tienen una importancia similar**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1690d2e7-e302-41cb-9713-9f228ad278e6",
   "metadata": {},
   "source": [
    "Guardamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ceb7cf3-76f0-4414-9185-948b8e32d19c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/SVM2-tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Guardar el modelo SVM entrenado\n",
    "joblib.dump(svm_model, 'modelos/SVM2.pkl')\n",
    "\n",
    "# Guardar el vectorizador TF-IDF entrenado\n",
    "joblib.dump(tfidf_vectorizer, 'modelos/SVM2-tfidf_vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b2a137-bef5-4eed-a904-7c20a3f73541",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Redes neuronales (6k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d07f36-b153-45ad-bee7-64bf0cd76fe9",
   "metadata": {},
   "source": [
    "Esta vez usaremos una red neuronal con tres capas densas, cada una seguida de una capa de abandono (dropout) para evitar el sobreajuste. Utilizamos la función de activación 'relu' en las capas ocultas y 'sigmoid' en la capa de salida para problemas de clasificación binaria. El optimizador Adam se utiliza para minimizar la pérdida de entropía cruzada binaria, y la exactitud (*accuracy*) se utiliza como métrica de evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e0994bd-4336-464e-ae53-6198c5404146",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rojas\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\rojas\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rojas\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rojas\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rojas\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rojas\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "##### Esto ya lo tengo del modelo anterior, por eso no lo ejecuto\n",
    "# Dividir los datos en características (X) y etiquetas (y)\n",
    "#X = habit['texto_destacado']\n",
    "#y = habit['alta_calidad']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Representación TF-IDF de las características de texto\n",
    "#tfidf_vectorizer = TfidfVectorizer(stop_words=custom_stopwords)\n",
    "#X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "#X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "##### A partir de aquí ya son cosas nuevas para este modelo de redes neuronales\n",
    "# Escalar las características numéricas\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_tfidf.toarray())\n",
    "X_test_scaled = scaler.transform(X_test_tfidf.toarray())\n",
    "\n",
    "# Crear el modelo de redes neuronales\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid') #Sigmoid es más adecuado para variables binarias\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "historyANN = model.fit(X_train_scaled, y_train, #Son las mismas del modelo anterior\n",
    "                    epochs=10, batch_size=32, validation_data=(X_test_scaled, y_test),\n",
    "                    verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2430fe-ea03-4573-99ca-25cd03078a8f",
   "metadata": {},
   "source": [
    "Encuentro los parámetros para comparar con modelo SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "457363cd-109f-452a-9494-a7ae85567660",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 2ms/step\n",
      "Accuracy: 0.8126142595978062\n",
      "Recall: 0.061224489795918366\n",
      "Precision: 0.36363636363636365\n",
      "F1 Score: 0.10480349344978165\n",
      "Confusion Matrix:\n",
      " [[877  21]\n",
      " [184  12]]\n"
     ]
    }
   ],
   "source": [
    "# Calcular las predicciones binarias del modelo en el conjunto de datos de prueba\n",
    "umbral = 0.5  # Umbral para convertir las probabilidades en etiquetas binarias\n",
    "y_pred_binario = [1 if pred >= umbral else 0 for pred in model.predict(X_test_scaled)]\n",
    "\n",
    "# Calcular las métricas de evaluación\n",
    "accuracyANN = accuracy_score(y_test, y_pred_binario)\n",
    "recallANN = recall_score(y_test, y_pred_binario)\n",
    "precisionANN = precision_score(y_test, y_pred_binario)\n",
    "f1ANN = f1_score(y_test, y_pred_binario)\n",
    "conf_matrixANN = confusion_matrix(y_test, y_pred_binario)\n",
    "\n",
    "# Imprimir las métricas\n",
    "print(\"Accuracy:\", accuracyANN)\n",
    "print(\"Recall:\", recallANN)\n",
    "print(\"Precision:\", precisionANN)\n",
    "print(\"F1 Score:\", f1ANN)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrixANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cefb5cf-2986-4c4e-bb25-27e9fc0f1235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: modelos/NN2-BCN6K\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: modelos/NN2-BCN6K\\assets\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Guardar el modelo\n",
    "model.save(\"modelos/NN2-BCN6K\")\n",
    "\n",
    "# Guardar el historial\n",
    "with open(\"modelos/NN2-BCN6k/history.pkl\", \"wb\") as f:\n",
    "    pickle.dump(historyANN.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bef2ea06-88fc-4994-af55-210723fbb2d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_habit6_tfidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Preprocesamiento del texto en 'texto_destacado' utilizando el mismo TfidfVectorizer y StandardScaler\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#X_habit6_tfidf = tfidf_vectorizer.transform(habit6['texto_destacado']) #### Esto ya no lo ejecuto porque ya lo hice con el modelo anterior\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m X_habit6_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_habit6_tfidf\u001b[38;5;241m.\u001b[39mtoarray())\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#### A partir de aquí ya es nuevo\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Predecir la calidad de los inmuebles en 'habit6' utilizando el modelo de redes neuronales ya entrenado\u001b[39;00m\n\u001b[0;32m      7\u001b[0m y_habit6_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_habit6_scaled)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_habit6_tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Preprocesamiento del texto en 'texto_destacado' utilizando el mismo TfidfVectorizer y StandardScaler\n",
    "#X_habit6_tfidf = tfidf_vectorizer.transform(habit6['texto_destacado']) #### Esto ya no lo ejecuto porque ya lo hice con el modelo anterior\n",
    "X_habit6_scaled = scaler.transform(X_habit6_tfidf.toarray())\n",
    "\n",
    "#### A partir de aquí ya es nuevo\n",
    "# Predecir la calidad de los inmuebles en 'habit6' utilizando el modelo de redes neuronales ya entrenado\n",
    "y_habit6_pred = model.predict(X_habit6_scaled)\n",
    "\n",
    "# Convertir las predicciones a etiquetas binarias (0 o 1) utilizando un umbral (por ejemplo, 0.5)\n",
    "umbral = 0.5\n",
    "acp_LLM_ANN = [1 if pred >= umbral else 0 for pred in y_habit6_pred] #acp de alta_calidad_predicha\n",
    "\n",
    "# Agregar una columna 'alta_calidad_predicha' al DataFrame 'habit6' con las predicciones del modelo\n",
    "habit6['acp-LLM-ANN'] = acp_LLM_ANN\n",
    "\n",
    "#coincidencias6 = (habit6['alta_calidad'] == habit6['acp-LLM-ANN']).sum()\n",
    "\n",
    "print(\"Cantidad de valores coincidentes:\", (habit6['alta_calidad'] == habit6['acp-LLM-ANN']).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2ab4d1-6903-4952-ab4b-82a9f5e5e12f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "4869/5467"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d14bf1-7b6d-45b3-9610-2116c9399015",
   "metadata": {},
   "source": [
    "Parece tener un rendimiento ligeramente menor que el **modelo SVM**. Guardamos los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422744e6-003c-4bd2-9083-dea025c3752a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Guardar el modelo entrenado\n",
    "model.save('modelos/LLM1-ANN')\n",
    "\n",
    "# Guardar el historial de entrenamiento\n",
    "dump(history, 'modelos/LLM1-ANN/history.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2811e9a2-f670-4daf-8efc-873c842c8e2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Random Forest (6k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44ccf4ec-4154-4f1d-9675-596bb4a03ad3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.823583180987203\n",
      "Recall: 0.04081632653061224\n",
      "Precision: 0.6153846153846154\n",
      "F1 Score: 0.07655502392344496\n",
      "Confusion Matrix:\n",
      " [[893   5]\n",
      " [188   8]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "\n",
    "#### Esto ya lo tengo\n",
    "\n",
    "# Dividir los datos en características (X) y etiquetas (y)\n",
    "#X = habit['texto_destacado']\n",
    "#y = habit['alta_calidad']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Representación TF-IDF de las características de texto\n",
    "#tfidf_vectorizer = TfidfVectorizer(stop_words=custom_stopwords)\n",
    "#X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "#X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "#### Esto ya es nuevo\n",
    "# Crear y entrenar el modelo de Random Forest\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predecir las etiquetas en el conjunto de prueba\n",
    "y_predRF = random_forest.predict(X_test_tfidf)\n",
    "\n",
    "# Calcular las métricas de evaluación\n",
    "accuracyRF = accuracy_score(y_test, y_predRF)\n",
    "recallRF = recall_score(y_test, y_predRF)\n",
    "precisionRF = precision_score(y_test, y_predRF)\n",
    "f1RF = f1_score(y_test, y_predRF)\n",
    "conf_matrixRF = confusion_matrix(y_test, y_predRF)\n",
    "\n",
    "# Imprimir las métricas para comparar con SVM y ANN\n",
    "print(\"Accuracy:\", accuracyRF)\n",
    "print(\"Recall:\", recallRF)\n",
    "print(\"Precision:\", precisionRF)\n",
    "print(\"F1 Score:\", f1RF)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrixRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c91cd550-a294-4fcd-97c5-767edf19db38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/RF2-BCN6K.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardar el modelo de Random Forest\n",
    "joblib.dump(random_forest, 'modelos/RF2-BCN6K.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205c2d43-ea76-49ca-bc1b-30f2e0449b26",
   "metadata": {},
   "source": [
    "# 4. Comparamos los resultados de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56aa2ed9-a9b9-4efa-825c-e22c9db3d0c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Modelo  Accuracy  Precision    Recall  F1 Score\n",
      "0    SVM  0.825411   0.666667  0.051020  0.094787\n",
      "1    ANN  0.812614   0.363636  0.061224  0.104803\n",
      "2     RF  0.823583   0.615385  0.040816  0.076555\n"
     ]
    }
   ],
   "source": [
    "# Crear un diccionario con los datos\n",
    "data = {\n",
    "    'Modelo': ['SVM', 'ANN', 'RF'],\n",
    "    'Accuracy': [accuracySVM, accuracyANN, accuracyRF],\n",
    "    'Precision': [precisionSVM, precisionANN, precisionRF],\n",
    "    'Recall': [recallSVM, recallANN, recallRF],\n",
    "    'F1 Score': [f1SVM, f1ANN, f1RF]\n",
    "}\n",
    "\n",
    "# Crear un DataFrame con los datos\n",
    "comparacion = pd.DataFrame(data)\n",
    "\n",
    "# Mostrar la tabla\n",
    "print(comparacion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c2cc10-d03e-48f6-8feb-1e2cc8434b4d",
   "metadata": {
    "tags": []
   },
   "source": [
    "- Precisión (Accuracy):\n",
    "    - La precisión es la proporción de predicciones correctas sobre el total de predicciones.\n",
    "    - Una precisión del 1.0 indica que todas las predicciones son correctas, mientras que una precisión del 0.0 indica que ninguna predicción es correcta.\n",
    "    - Es una métrica general del rendimiento del modelo, pero puede ser engañosa si hay un desequilibrio en las clases objetivo.\n",
    "\n",
    "- Recall (Exhaustividad):\n",
    "    - La exhaustividad es la proporción de positivos reales que se identificaron correctamente.\n",
    "    - Una exhaustividad del 1.0 indica que todas las instancias positivas se han identificado correctamente, mientras que una exhaustividad del 0.0 indica que ninguna instancia positiva se ha identificado correctamente.\n",
    "    - Es útil cuando la identificación de instancias positivas es crítica y no se pueden permitir falsos negativos.\n",
    "\n",
    "- Precisión (Precision):\n",
    "    - La precisión es la proporción de instancias positivas predichas que fueron correctamente identificadas.\n",
    "    - Una precisión del 1.0 indica que todas las instancias predichas como positivas son verdaderas positivas, mientras que una precisión del 0.0 indica que ninguna instancia predicha como positiva es realmente positiva.\n",
    "    - Es útil cuando es importante evitar falsos positivos.\n",
    "\n",
    "- F1 Score:\n",
    "    - El puntaje F1 es la media armónica de precisión y exhaustividad.\n",
    "    - Proporciona un equilibrio entre precisión y exhaustividad, lo que lo hace útil cuando se desea tener un buen rendimiento en ambas métricas.\n",
    "    - Un puntaje F1 del 1.0 indica un equilibrio perfecto entre precisión y exhaustividad.\n",
    "\n",
    "- Matriz de Confusión:\n",
    "    - La matriz de confusión es una tabla que describe la calidad de las predicciones del modelo.\n",
    "    - Proporciona una descripción detallada de los resultados de clasificación, mostrando el número de verdaderos positivos, verdaderos negativos, falsos positivos y falsos negativos.\n",
    "    - Es útil para identificar dónde el modelo está cometiendo errores y para evaluar el desempeño en cada clase por separado."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
